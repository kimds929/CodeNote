import minari
import json

# ì €ì¥í•  íŒŒì¼ ì´ë¦„
file_name = "minari_datasets_list.txt"

print("Minari ì›ê²© ë°ì´í„°ì…‹ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")

try:
    # 1. Minariì˜ ì „ì²´ ì›ê²© ë°ì´í„°ì…‹ ëª©ë¡ì„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    remote_datasets = minari.list_remote_datasets()
    print("ëª©ë¡ì„ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")

    # 2. ê°€ì ¸ì˜¨ ëª©ë¡ì„ ë³´ê¸° ì¢‹ê²Œ ì •ë ¬í•˜ì—¬ txt íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    with open(file_name, "w", encoding="utf-8") as f:
        # json.dumpë¥¼ ì‚¬ìš©í•˜ë©´ ë”•ì…”ë„ˆë¦¬ë¥¼ ê¹”ë”í•˜ê²Œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        json.dump(remote_datasets, f, indent=4, ensure_ascii=False)
    print(f"ì „ì²´ ëª©ë¡ì„ '{file_name}' íŒŒì¼ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

    # 3. ë°ì´í„°ì…‹ ì´ë¦„(key)ë“¤ ì¤‘ì—ì„œ 'hopper'ê°€ í¬í•¨ëœ ê²ƒì´ ìˆëŠ”ì§€ ì°¾ìŠµë‹ˆë‹¤.
    found_hopper_datasets = []
    for name in remote_datasets.keys():
        if 'hopper' in name:
            found_hopper_datasets.append(name)

    # 4. ìµœì¢… ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    print("\n--- 'hopper' ë°ì´í„°ì…‹ ê²€ìƒ‰ ê²°ê³¼ ---")
    if found_hopper_datasets:
        print(f"âœ… ì´ {len(found_hopper_datasets)}ê°œì˜ 'hopper' ë°ì´í„°ì…‹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        for dataset_name in found_hopper_datasets:
            print(f"  -> {dataset_name}")
    else:
        print("âŒ 'hopper'ê°€ í¬í•¨ëœ ë°ì´í„°ì…‹ì„ ì›ê²© ëª©ë¡ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print("   (ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ë¬¸ì œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ ë³´ì„¸ìš”.)")

except Exception as e:
    print(f"\nìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    print(f"ì—ëŸ¬: {e}")
    

    
import minari
import numpy as np

# Load the local dataset
dataset = minari.load_dataset("mujoco/hopper/expert-v0", download=True)

print("--- âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ! ---")

# Recover the environment
env = dataset.recover_environment()

# 1. Get all episodes by treating the dataset object as a list
episodes = list(dataset)

# 2. Concatenate the data from each episode
observations = np.concatenate([e.observations for e in episodes])
actions = np.concatenate([e.actions for e in episodes])
rewards = np.concatenate([e.rewards for e in episodes])
terminations = np.concatenate([e.terminations for e in episodes])
truncations = np.concatenate([e.truncations for e in episodes])

# 3. Manually create `next_observations` by shifting the `observations` array
# np.roll with shift=-1 moves each element one position to the front
next_observations = np.roll(observations, -1, axis=0)

# The 'done' flag is the combination of terminations and truncations
dones = terminations | truncations

# Note: For the last step of each episode (where dones[i] is True), 
# the corresponding next_observations[i] is the start of the *next* episode.
# Most RL algorithms handle this correctly by checking the 'done' flag.

print(f"\në°ì´í„°ì…‹ ID: {dataset.spec.dataset_id}")
print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(observations)}")

# --- Print first 5 samples ---
print("\n--- ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ) ---")
for i in range(5):
    print(f"[{i+1}]")
    print(f"  - Observation (ìƒíƒœ): {observations[i].round(2)}")
    print(f"  - Action (í–‰ë™): {actions[i].round(2)}")
    print(f"  - Reward (ë³´ìƒ): {rewards[i]}")
    # We now use the combined 'dones' flag
    print(f"  - Done (ì¢…ë£Œ ì—¬ë¶€): {dones[i]}")
    print(f"  - Next Observation (ë‹¤ìŒ ìƒíƒœ): {next_observations[i].round(2)}")
    print("-" * 20)

env.close()




import minari
import numpy as np

def calculate_average_return(dataset_name: str) -> float:
    """
    ë°ì´í„°ì…‹ ì´ë¦„ì´ ì£¼ì–´ì§€ë©´, í•´ë‹¹ ë°ì´í„°ì…‹ì˜ 
    ì—í”¼ì†Œë“œë‹¹ í‰ê·  ëˆ„ì  ë³´ìƒ(Average Return)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    print(f"'{dataset_name}' ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    try:
        # 1. ë°ì´í„°ì…‹ ë¡œë“œ (ë¡œì»¬ì— ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ)
        dataset = minari.load_dataset(dataset_name, download=True)
        
        # 2. ëª¨ë“  ì—í”¼ì†Œë“œ ê°€ì ¸ì˜¤ê¸°
        episodes = list(dataset)
        
        # 3. ê° ì—í”¼ì†Œë“œì˜ ëˆ„ì  ë³´ìƒ ê³„ì‚°
        #    - episode.rewardsëŠ” í•´ë‹¹ ì—í”¼ì†Œë“œì˜ ëª¨ë“  ë³´ìƒê°’ì„ ë‹´ê³  ìˆëŠ” ë°°ì—´ì…ë‹ˆë‹¤.
        #    - np.sum()ìœ¼ë¡œ ê° ì—í”¼ì†Œë“œì˜ ë³´ìƒ ì´í•©ì„ êµ¬í•©ë‹ˆë‹¤.
        episode_returns = [np.sum(episode.rewards) for episode in episodes]
        
        # 4. ëª¨ë“  ì—í”¼ì†Œë“œì˜ ëˆ„ì  ë³´ìƒì— ëŒ€í•œ í‰ê·  ê³„ì‚°
        average_return = np.mean(episode_returns)
        
        print(f"'{dataset_name}' ì²˜ë¦¬ ì™„ë£Œ.")
        return average_return

    except Exception as e:
        print(f"'{dataset_name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 0.0

# --- ë¹„êµ ì‹¤í–‰ ---
print("ë°ì´í„°ì…‹ë³„ í‰ê·  ëˆ„ì  ë³´ìƒ ë¹„êµë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\n")

# ë¹„êµí•  ë°ì´í„°ì…‹ ì´ë¦„
medium_dataset_name = "mujoco/hopper/medium-v0"
expert_dataset_name = "mujoco/hopper/expert-v0"

# ê° ë°ì´í„°ì…‹ì˜ í‰ê·  ëˆ„ì  ë³´ìƒ ê³„ì‚°
avg_return_medium = calculate_average_return(medium_dataset_name)
print("-" * 30)
avg_return_expert = calculate_average_return(expert_dataset_name)

# --- ìµœì¢… ê²°ê³¼ ì¶œë ¥ ---
print("\n--- ìµœì¢… ë¹„êµ ê²°ê³¼ ---")
print(f"ğŸƒ Medium ë°ì´í„°ì…‹ì˜ í‰ê·  ëˆ„ì  ë³´ìƒ: {avg_return_medium:.2f}")
print(f"ğŸ† Expert ë°ì´í„°ì…‹ì˜ í‰ê·  ëˆ„ì  ë³´ìƒ: {avg_return_expert:.2f}")

if avg_return_expert > avg_return_medium:
    print("\nê²°ë¡ : Expert ì •ì±…ì´ Medium ì •ì±…ë³´ë‹¤ ì—í”¼ì†Œë“œ ì „ì²´ì—ì„œ í›¨ì”¬ ë†’ì€ ì´ì ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.")
else:
    print("\nê²°ë¡ : ì˜ˆìƒê³¼ ë‹¬ë¦¬ Medium ì •ì±…ì˜ í‰ê·  ì´ì ì´ ë” ë†’ê²Œ ë‚˜ì™”ìŠµë‹ˆë‹¤. (ë°ì´í„° í™•ì¸ í•„ìš”)")





import gymnasium as gym

# 1. Minari ë°ì´í„°ì…‹ ë¡œë“œ
dataset = minari.load_dataset("mujoco/hopper/expert-v0", download=True)
episodes_data = list(dataset)

env = gym.make(dataset.spec.env_spec.id, render_mode='human')  # MuJoCo viewer ì‹¤í–‰ì„ ìœ„í•´ 'human' ì„¤ì •

obs, info = env.reset()
for action in episodes_data[0].actions:
    # action = env.action_space.sample()  # ë¬´ì‘ìœ„ í–‰ë™
    obs, reward, terminated, truncated, info = env.step(action)
    if terminated or truncated:
        # obs, info = env.reset()
        break
env.close()

